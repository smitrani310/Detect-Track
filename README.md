# Detect-Track

A comprehensive, modular object detection and tracking system with **enterprise-grade DeepStream-style pipeline** featuring TensorRT GPU acceleration, automatic PyTorch fallback, and multi-threaded architecture for maximum performance.

## Features

### üöÄ **Dual Pipeline Architecture**
- **üî• DeepStream-Style Pipeline** - Enterprise-grade with TensorRT GPU acceleration (22+ FPS)
- **üêç Standard Pipeline** - Reliable PyTorch-based processing (17+ FPS)
- **‚ö° Automatic Failover** - Seamless switching between TensorRT and PyTorch
- **üßµ Multi-threaded** - Parallel capture, inference, and display threads

### üéØ Detection Models
- **YOLOv5** (nano, small) - Fast and efficient
- **YOLOv7** - High accuracy  
- **YOLOv8** (nano, small) - Latest YOLO architecture
- **üî• TensorRT Optimization** - GPU-accelerated inference engines
- Easy model switching at runtime

### üéØ Tracking Algorithms
- **NvDCF** - OpenCV's Normalized Cross-Correlation tracker
- **DeepSORT** - Deep learning-based tracking with re-identification
- **BOTSort** - Motion prediction-based tracking
- All trackers support:
  - Continuing tracks for up to N frames without detections
  - Recovering object identity after partial occlusions

### üéØ Input Sources
- **Live Camera** - Real-time webcam input
- **Video Files** - Support for various video formats
- Configurable resolution and frame rate

### üéØ Advanced Features
- **üî• TensorRT GPU Acceleration** - Maximum performance inference engines
- **‚ö° Automatic Failover** - PyTorch fallback for robust operation
- **üßµ Multi-threaded Architecture** - Parallel processing pipelines
- **üìä Enterprise Monitoring** - Detailed performance statistics and profiling
- **Real-time switching** between models and trackers
- **Comprehensive logging** of detections, tracks, and metrics
- **Video output** with annotations
- **JSON export** of results
- **Interactive controls**

## Pipeline Architecture

The system offers **two high-performance pipelines** with automatic failover:

### üî• **DeepStream-Style Pipeline** (Enterprise)
```
Multi-threaded GPU Pipeline:
üìπ Capture Thread ‚Üí üî• TensorRT Inference ‚Üí üéØ Tracking ‚Üí üìä Display Thread
                      ‚Üì (fallback)
                   üêç PyTorch Inference
```

**Features:**
- **TensorRT GPU acceleration** - Maximum inference speed  
- **Multi-threaded architecture** - Parallel capture, inference, display
- **Automatic PyTorch fallback** - Robust error handling
- **Enterprise monitoring** - Detailed performance profiling
- **GPU memory management** - Optimized buffer pools

### üêç **Standard Pipeline** (Reliable)
```
Single-threaded Reliable Pipeline:
1. Frame Extraction ‚Üí 2. Detection ‚Üí 3. Conversion ‚Üí 4. Tracking ‚Üí 5. Logging
```

**Features:**
- **PyTorch-based inference** - Proven stability
- **Real-time switching** - Dynamic model/tracker changes  
- **Interactive controls** - Runtime configuration
- **Comprehensive logging** - Detailed output files

## Installation

### Prerequisites
- Python 3.8+
- **CUDA 11.0+** (required for DeepStream pipeline)
- **NVIDIA GPU** with CUDA support (for TensorRT acceleration)

### Install Dependencies
```bash
pip install -r requirements.txt
```

### üî• **DeepStream Pipeline Setup** (For Maximum Performance)
For enterprise-grade TensorRT acceleration:

```bash
# Install TensorRT (for GPU acceleration)
pip install nvidia-tensorrt

# Install PyCUDA (for GPU memory management)  
pip install pycuda

# Verify TensorRT installation
python -c "import tensorrt as trt; print(f'TensorRT {trt.__version__} ready')"
```

**Note:** DeepStream pipeline automatically falls back to PyTorch if TensorRT is unavailable.

### Additional Setup for YOLOv7
```bash
# YOLOv7 requires additional setup via torch.hub
python -c "import torch; torch.hub.load('WongKinYiu/yolov7', 'yolov7', trust_repo=True)"
```

## Quick Start

### üî• **DeepStream Pipeline** (Maximum Performance)
```bash
# Enterprise-grade GPU acceleration
python main_deepstream.py --camera --tracker botsort

# Video file with TensorRT acceleration  
python main_deepstream.py --video path/to/your/video.mp4 --model yolov8n

# Custom precision and verbose logging
python main_deepstream.py --camera --precision fp16 --verbose
```

### üêç **Standard Pipeline** (Reliable & Interactive)
```bash
# Use camera with default settings
python main.py --camera

# Use video file
python main.py --video path/to/your/video.mp4

# Specify model and tracker
python main.py --camera --model yolov8s --tracker deepsort
```

### üìä **Performance Comparison**
| Pipeline | FPS | Features | Best For |
|----------|-----|----------|----------|
| **DeepStream** | 22+ FPS | TensorRT, Multi-threading | Production, High throughput |
| **Standard** | 17+ FPS | Interactive, Switching | Development, Flexibility |

### Interactive Mode
```bash
# Enable runtime switching of models and trackers
python main.py --camera --interactive
```

In interactive mode, you can:
- Press `1-5` to switch between YOLO models
- Press `n`, `d`, `b` to switch between trackers
- Press `s` for status, `h` for help, `q` to quit

## Configuration

The system uses YAML configuration files. See `src/config/config.yaml` for all options:

```yaml
# Video Input
video:
  source: 'camera'  # or 'file'
  camera:
    device_id: 0
    width: 640
    height: 480
  file:
    path: 'path/to/video.mp4'

# Detection
detection:
  model: 'yolov8n'  # yolov5n, yolov5s, yolov7, yolov8n, yolov8s
  confidence_threshold: 0.5

# Tracking
tracking:
  algorithm: 'deepsort'  # nvdcf, deepsort, botsort
  max_lost_frames: 30
```

### Custom Configuration
```bash
python main.py --config custom_config.yaml
```

## Advanced Usage

### Command Line Options

#### üî• **DeepStream Pipeline** (`main_deepstream.py`)
```bash
python main_deepstream.py [OPTIONS]

Options:
  --camera              Use camera input
  --video PATH          Video file path
  --camera-id INT       Camera device ID (default: 0)
  --model MODEL         YOLO model (yolov5n|yolov8n|yolov8s)
  --tracker TRACKER     Tracker (botsort|nvdcf)
  --precision PRECISION TensorRT precision (fp32|fp16|int8)
  --confidence FLOAT    Detection confidence threshold
  --output-dir PATH     Output directory for results
  --no-display         Headless mode (no video display)
  --verbose            Enable detailed logging and profiling
```

#### üêç **Standard Pipeline** (`main.py`)
```bash
python main.py [OPTIONS]

Options:
  --config PATH          Custom configuration file
  --camera              Force camera input
  --video PATH          Video file path
  --model MODEL         YOLO model (yolov5n|yolov5s|yolov7|yolov8n|yolov8s)
  --tracker TRACKER     Tracker (nvdcf|deepsort|botsort)
  --no-display         Headless mode (no video display)
  --interactive        Enable runtime model/tracker switching
  --output-dir PATH    Output directory for results
  --confidence FLOAT   Detection confidence threshold
  --verbose            Enable debug logging
```

### Examples

#### üî• **DeepStream Pipeline Examples**
```bash
# Maximum performance real-time processing
python main_deepstream.py --camera --tracker botsort --precision fp16

# High-throughput video processing
python main_deepstream.py --video sample.mp4 --model yolov8s --verbose

# Headless production processing  
python main_deepstream.py --video input.mp4 --no-display --output-dir results/

# Enterprise monitoring with detailed stats
python main_deepstream.py --camera --verbose --tracker botsort
```

#### üêç **Standard Pipeline Examples**  
```bash
# High-accuracy setup with interactive controls
python main.py --video sample.mp4 --model yolov8s --tracker deepsort --interactive

# Fast real-time with runtime switching
python main.py --camera --model yolov5n --tracker nvdcf --interactive

# Development and testing
python main.py --video input.mp4 --no-display --output-dir results/

# Custom configuration
python main.py --config configs/high_precision.yaml --interactive
```

## Performance Benchmarks

### üî• **DeepStream Pipeline Performance**
| Tracker | FPS | Inference Time | Best Use Case |
|---------|-----|----------------|---------------|
| **BOTSort** | 22+ FPS | 31ms | Production, robust tracking |
| **NvDCF** | 25+ FPS | 28ms | High-speed, lightweight |

### üêç **Standard Pipeline Performance**  
| Tracker | FPS | Features | Best Use Case |
|---------|-----|----------|---------------|
| **BOTSort** | 17+ FPS | Motion prediction, robust | Development, testing |
| **NvDCF** | 20+ FPS | Fast, lightweight | Real-time applications |
| **DeepSORT** | 15+ FPS | Re-identification, occlusion handling | High accuracy needs |

### üìä **Tracker Feature Comparison**
| Tracker | Speed | Accuracy | Features |
|---------|-------|----------|----------|
| **BOTSort** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | Motion prediction, robust tracking, confirmed tracks |
| **NvDCF** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | Fast, lightweight, good for real-time |
| **DeepSORT** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | Re-identification, handles occlusions well |

## Model Comparison

| Model | Speed | Accuracy | Size | Best Use Case |
|-------|-------|----------|------|---------------|
| **YOLOv5n** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | 1.9MB | Real-time applications |
| **YOLOv5s** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | 14MB | Balanced speed/accuracy |
| **YOLOv7** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | 75MB | High accuracy requirements |
| **YOLOv8n** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | 3.2MB | Latest nano model |
| **YOLOv8s** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | 11MB | Latest small model |

## Output Files

The system generates several output files in the specified output directory:

```
outputs/
‚îú‚îÄ‚îÄ tracked_video.mp4      # Annotated video with detections and tracks
‚îú‚îÄ‚îÄ detections.json        # Per-frame detection results
‚îú‚îÄ‚îÄ tracks.json           # Tracking results with track IDs
‚îî‚îÄ‚îÄ metrics.csv          # Performance metrics (FPS, processing time)
```

### Sample JSON Output

**Detections:**
```json
[
  {
    "frame_id": 1,
    "timestamp": 1699123456.789,
    "bbox": [100, 150, 200, 300],
    "confidence": 0.85,
    "class_id": 0,
    "class_name": "person"
  }
]
```

**Tracks:**
```json
[
  {
    "frame_id": 1,
    "timestamp": 1699123456.789,
    "track_id": 1,
    "bbox": [100, 150, 200, 300],
    "confidence": 0.85,
    "class_id": 0,
    "class_name": "person",
    "is_confirmed": true,
    "duration": 15,
    "frames_since_update": 0
  }
]
```

## Architecture

```
src/
‚îú‚îÄ‚îÄ config/           # Configuration management
‚îú‚îÄ‚îÄ core/            # Base classes and data structures  
‚îú‚îÄ‚îÄ detection/       # YOLO model implementations
‚îú‚îÄ‚îÄ tracking/        # Tracking algorithm implementations
‚îú‚îÄ‚îÄ video/          # Video input sources
‚îú‚îÄ‚îÄ utils/          # Logging and utilities
‚îú‚îÄ‚îÄ pipeline/       # Standard pipeline orchestrator
‚îî‚îÄ‚îÄ deepstream/     # üî• Enterprise DeepStream pipeline
    ‚îú‚îÄ‚îÄ deepstream_pipeline.py  # Multi-threaded GPU pipeline
    ‚îú‚îÄ‚îÄ tensorrt_yolo.py        # TensorRT inference engine
    ‚îî‚îÄ‚îÄ __init__.py             # Module interface

üìÅ Entry Points:
‚îú‚îÄ‚îÄ main.py              # üêç Standard pipeline entry point
‚îú‚îÄ‚îÄ main_deepstream.py   # üî• DeepStream pipeline entry point  
‚îî‚îÄ‚îÄ requirements.txt     # Python dependencies
```

## Key Features Implementation

### ‚úÖ Multi-Model Support
Switch between YOLOv5, v7, and v8 models at runtime without restarting.

### ‚úÖ Robust Tracking
All trackers implement:
- Track continuation for up to N frames without detections
- Identity recovery after occlusions
- Confirmed track management

### ‚úÖ Flexible Input
Support for both live camera and video file inputs with configurable parameters.

### ‚úÖ Comprehensive Logging
- Frame-by-frame detection and tracking results
- Performance metrics and timing
- Annotated video output
- JSON export for analysis

### ‚úÖ Real-time Performance
Optimized pipeline with configurable frame skipping and resizing for real-time performance.

## üì∫ Video Resolution Handling

The system handles video resolution differently based on the input source:

### üé• **Camera Sources**
- **Resizing allowed** for performance optimization
- Configurable via `performance.resize_input` and `performance.target_size`
- Default: Resize to 640x640 for consistent processing
- Example: Camera input at 1920x1080 ‚Üí Resized to 640x640

### üé¨ **Video Files**  
- **Original resolution preserved** automatically
- Ignores `performance.resize_input` setting to maintain video quality
- No interpolation artifacts from resizing
- Example: Video file at 1920x1080 ‚Üí Processed at 1920x1080

### ‚öôÔ∏è **Configuration**
```yaml
performance:
  resize_input: true  # Only affects camera sources
  target_size: [640, 640]  # Only applied to camera input
```

This ensures optimal performance for live camera feeds while preserving the original quality and aspect ratio of video files.

## üî• DeepStream Configuration

The DeepStream pipeline supports additional configuration options:

```yaml
# DeepStream-specific settings
detection:
  tensorrt_precision: 'fp16'  # fp32, fp16, int8
  workspace_size: 1073741824  # 1GB TensorRT workspace

# Multi-threading settings  
performance:
  gpu_memory_pool_size: 10    # Number of GPU memory buffers
  max_queue_size: 30          # Frame queue buffer size
  
# Enterprise monitoring
logging:
  enable_profiling: true      # Detailed performance stats
  log_inference_times: true   # Per-frame timing
```

## Troubleshooting

### Common Issues

#### üî• **DeepStream Pipeline Issues**

1. **TensorRT not found**
   ```bash
   pip install nvidia-tensorrt pycuda
   # Pipeline automatically falls back to PyTorch
   ```

2. **TensorRT inference fails**
   ```bash
   python main_deepstream.py --verbose  # Check detailed logs
   # System automatically uses PyTorch fallback
   ```

3. **CUDA out of memory**
   ```bash
   python main_deepstream.py --model yolov5n --precision fp16
   ```

#### üêç **Standard Pipeline Issues**

1. **Camera not found**
   ```bash
   python main.py --camera --verbose  # Check debug logs
   ```

2. **Low FPS**
   - Use smaller model (yolov5n, yolov8n)
   - Enable frame skipping in config
   - Reduce input resolution

3. **DeepSORT import error**
   ```bash
   pip install deep-sort-realtime
   # Use BOTSort instead: --tracker botsort
   ```

4. **OpenCV tracker issues**
   ```bash
   pip install opencv-contrib-python  # For NvDCF tracker
   ```

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## License

This project is licensed under the Apache License 2.0 License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

### Core Technologies
- **YOLOv5**: [ultralytics/yolov5](https://github.com/ultralytics/yolov5)
- **YOLOv7**: [WongKinYiu/yolov7](https://github.com/WongKinYiu/yolov7)
- **YOLOv8**: [ultralytics/ultralytics](https://github.com/ultralytics/ultralytics)
- **DeepSORT**: [levan92/deep_sort_realtime](https://github.com/levan92/deep_sort_realtime)

### Enterprise GPU Acceleration
- **NVIDIA TensorRT**: High-performance deep learning inference
- **NVIDIA CUDA**: Parallel computing platform and programming model
- **PyCUDA**: Python bindings for CUDA
- **NVIDIA DeepStream**: Inspiration for enterprise-grade pipeline architecture

---

**üöÄ Built with ‚ù§Ô∏è for computer vision enthusiasts - Now with enterprise-grade GPU acceleration!**